{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Word Embeddings Training Tutorial\n",
    "This tutorial shows how to train word embeddings using word2vec. The python package used is Gensim\n",
    "\n",
    "https://radimrehurek.com/gensim/\n",
    "\n",
    "We are going to use the movie review data sets to train our own word embbedings and we are going to compare it with the pretreained word embeddings from google.\n",
    "\n",
    "- Movie Review data set\n",
    "http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "\n",
    "- Google pre-trained word embeddings using word2vec\n",
    "https://code.google.com/archive/p/word2vec/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "The first step as always is loading the data and processing in a suitable way for the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Not enough RAM\n",
    "If you do not have enough RAM a SentenceIterator class was created to avoid running out of RAM while training the model. Run the code below only if you do not have enough RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sentence_iterator import SentenceIterator\n",
    "#file_path = \"/home/jose/aclImdb_data/all_data\"\n",
    "#sentences = SentenceIterator(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Enough RAM\n",
    "If you have enough RAM is better to read the files, split them into sentences and save a pickle file for future use. You only need to run this code once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the files\n",
    "#import pickle\n",
    "#import os\n",
    "#from nltk import sent_tokenize\n",
    "#from nltk import word_tokenize\n",
    "\n",
    "pickle_file = \"imdb_extracted_sentences.pickle\"\n",
    "#file_path = \"/home/jose/aclImdb_data/all_data\"\n",
    "#sentences = []\n",
    "#for fname in os.listdir(file_path):\n",
    "#    for sent in sent_tokenize(open(os.path.join(file_path, fname),'r').read()):\n",
    "#        sentences.append(word_tokenize(sent))\n",
    "#\n",
    "#with open(pickle_file, 'wb') as f: \n",
    "#    pickle.dump(sentences, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you already save the pickle file you do not need to run the code above, only load the pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(pickle_file,\"rb\") as f:\n",
    "    sentences = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train the model\n",
    "The algorithm require us to specify some hyper parameters such as\n",
    "- min_count: is the minimum number of times a word needs to occur in the corpus to be used by the algorithm during training\n",
    "- embeddings_size: this is the size of the real valued vector that is going to represent each unique word in the corpus\n",
    "- percent: this is the percentage of sentences to process. Thi is useful when you want to obtain a quick result with a subset of the data\n",
    "- workers: number of workers for parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the library\n",
    "import gensim\n",
    "import math\n",
    "\n",
    "min_count = 10\n",
    "embeddings_size = 100\n",
    "percent = 0.15\n",
    "workers = 20\n",
    "model = gensim.models.Word2Vec(sentences[0:math.floor(percent*len(sentences))], min_count=min_count, workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving the model\n",
    "model.save(\"word2vec_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Inspecting the model\n",
    "It is useful to see the semantic similarity of some words as an intrisic evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the vocabulary: 16705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('girl', 0.8700416088104248),\n",
       " ('man', 0.8666628003120422),\n",
       " ('lady', 0.8453189134597778),\n",
       " ('boy', 0.8107814788818359),\n",
       " ('soldier', 0.7831786870956421),\n",
       " ('doctor', 0.7675391435623169),\n",
       " ('child', 0.732384443283081),\n",
       " ('witch', 0.7167837619781494),\n",
       " ('scientist', 0.7161659002304077),\n",
       " ('cop', 0.6994512677192688)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Size of the vocabulary: \" + str(len(model.wv.vocab)))\n",
    "model.most_similar(positive=['woman'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65367832859740349"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('dog', 'fox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.18082204, -0.05777469,  0.28638139, -0.43027464, -0.3152011 ,\n",
       "        0.06283583,  0.39537835, -0.96961647, -0.11849733, -0.01840558,\n",
       "       -0.32806531,  0.03565818, -0.10399359,  0.35991848,  0.222792  ,\n",
       "        0.07531917, -0.1085555 , -0.15583414, -0.06360928,  0.02611457,\n",
       "       -0.10706156, -0.54339021,  0.05757902, -0.12644817, -0.22230825,\n",
       "        0.7339049 ,  0.16918948,  0.28775319, -0.13272724,  0.19950433,\n",
       "       -0.12631072, -0.2535795 , -0.0032704 ,  0.11509611, -0.02309781,\n",
       "       -0.05108172, -0.05151635, -0.40891787,  0.21989913,  0.11440427,\n",
       "       -0.0152181 , -0.27502182, -0.63500124, -0.19826609, -0.06698717,\n",
       "        0.21478115, -0.03544712,  0.44662356, -0.08495852, -0.15820642,\n",
       "       -0.06566726, -0.13116595, -0.22253287,  0.18820772, -0.29603323,\n",
       "        0.13104057,  0.0482242 ,  0.0267632 , -0.09839885,  0.20925035,\n",
       "       -0.39864907,  0.0827572 ,  0.26668873,  0.25393853,  0.20875359,\n",
       "        0.3907806 , -0.26723692, -0.44289762, -0.47170168, -0.05919804,\n",
       "       -0.41022068, -0.12582581,  0.01979949,  0.40091181,  0.14673372,\n",
       "       -0.24300791, -0.20229159, -0.28645724,  0.36394048, -0.13425441,\n",
       "       -0.19225675,  0.16551618, -0.08015994,  0.08279146,  0.09462674,\n",
       "        0.1191515 , -0.6228379 ,  0.16794647, -0.22201939,  0.02466247,\n",
       "       -0.34441742,  0.18787476, -0.06805906, -0.12455883,  0.01058879,\n",
       "       -0.17897248,  0.71190929, -0.06027322,  0.45131028,  0.76099688], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['animal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load a pre-trained Model\n",
    "In this case we are going to load google pre-trained model.\n",
    "\n",
    "The description of the model can be found in\n",
    "https://code.google.com/archive/p/word2vec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "google_model = gensim.models.KeyedVectors.load_word2vec_format('/data2/data/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Inspect the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the Vocabulary: 3000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('man', 0.7664012312889099),\n",
       " ('girl', 0.7494640946388245),\n",
       " ('teenage_girl', 0.7336829900741577),\n",
       " ('teenager', 0.631708562374115),\n",
       " ('lady', 0.6288785934448242),\n",
       " ('teenaged_girl', 0.6141784191131592),\n",
       " ('mother', 0.607630729675293),\n",
       " ('policewoman', 0.6069462299346924),\n",
       " ('boy', 0.5975908041000366),\n",
       " ('Woman', 0.5770983099937439)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Size of the Vocabulary: \" + str(len(google_model.vocab)))\n",
    "google_model.most_similar(positive=['woman'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52753879318272923"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_model.similarity('dog', 'fox')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pacific tensorflow13",
   "language": "python",
   "name": "tensorflow13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
